import random
import os
from decimal import *


configfile: "config.yaml"

seed_list=[format(x, '02d') for x in range(1,21,1)]

hap_list = ["hap1", "hap2"]

#name of sample 
sample_prefix=config["sample_prefix"]

# path to seed hap 1 & 2

SEED_HAP_1=config["genomes"]["SEED_HAP_1"]["fasta"]
SEED_HAP_2=config["genomes"]["SEED_HAP_2"]["fasta"]

SEED_HAP_1_chromnum = ["%04d" % x for x in range(1,config["genomes"]["SEED_HAP_1"]["chrom_num"]+1)]
SEED_HAP_2_chromnum = ["%04d" % x for x in range(1,config["genomes"]["SEED_HAP_2"]["chrom_num"]+1)]

READ_LENGTH=config["read_length"]

#busco db to use
LINEAGE=config["LINEAGE"]


wildcard_constraints:
    hap="hap[0-9]",
    seeds="[0-9]+",
    chr_nm1="[0-9]{4}",
    chr_nm2="[0-9]{4}"


def output_looper(seed_name, pref, hap, chrom_num, cat=""):
    for i in chrom_num:
        if cat == "maf":
            yield "/share/pool/simulations_collomics/{4}/{0}_{1}_{2}/{0}_{1}_{3}.maf".format(seed_name, pref, hap, i, "{READ_LENGTH}")
        elif cat == "ref":
            yield "/share/pool/simulations_collomics/{4}/{0}_{1}_{2}/{0}_{1}_{3}.ref".format(seed_name, pref, hap, i, "{READ_LENGTH}")
        elif cat == "sam":
            yield "/share/pool/simulations_collomics/{4}/{0}_{1}_{2}/{0}_{1}_{3}.sam".format(seed_name, pref, hap, i, "{READ_LENGTH}")
        elif cat == "bam":
            yield "/share/pool/simulations_collomics/{4}/{0}_{1}_{2}/{0}_{1}_{3}.bam".format(seed_name, pref, hap, i, "{READ_LENGTH}")
        elif cat == "fastq.gz":
            yield "/share/pool/simulations_collomics/{4}/{0}_{1}_{2}/{0}_{1}_{3}.fastq.gz".format(seed_name, pref, hap, i, "{READ_LENGTH}")

rule all:
    input:
        expand("/share/pool/simulations_collomics/%s/{seeds}_{sample}_{hap}/{seeds}_{sample}_{chr_nm1}.fastq.gz" %READ_LENGTH, seeds=seed_list, hap=hap_list[0], chr_nm1=SEED_HAP_1_chromnum,sample=sample_prefix),
        expand("/share/pool/simulations_collomics/%s/{seeds}_{sample}_{hap}/{seeds}_{sample}_{chr_nm2}.fastq.gz" %READ_LENGTH, seeds=seed_list, hap=hap_list[1], chr_nm2=SEED_HAP_2_chromnum,sample=sample_prefix),
        expand("%s/busco/{sample}/run_{db}/missing_busco_list.tsv" %READ_LENGTH, db=LINEAGE, sample=sample_prefix),
        "%s/fastq_files/all_pbsim.fastq.gz" %READ_LENGTH,
        "%s/stats/backmapping_stats.txt" %READ_LENGTH,
        "%s/stats/assembly_stats.txt" %READ_LENGTH,
        "%s/stats/read_stats.txt" %READ_LENGTH

rule run_sim_hap1:
    input:
        genome=SEED_HAP_1
    output:
        bam=temp(output_looper("{seeds}", "{sample}", hap_list[0], SEED_HAP_1_chromnum, cat="sam")),
        ref=temp(output_looper("{seeds}", "{sample}", hap_list[0], SEED_HAP_1_chromnum, cat="ref")),
        maf=temp(output_looper("{seeds}", "{sample}", hap_list[0], SEED_HAP_1_chromnum, cat="maf"))
    params:
        seed_id="{seeds}",
        prefix_sim="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap1/{seeds}_{sample}",
        lngth=config["read_length"],
        dpth=config["depth"]
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        module load pbsim3/3.0.0
        pbsim --prefix {params.prefix_sim} --strategy wgs --genome {input.genome} \
        --depth {params.dpth} --method errhmm --errhmm /share/scientific_src/pbsim3/3.0.0/data/ERRHMM-SEQUEL.model \
        --length-mean {params.lngth} --pass-num 10 --seed {params.seed_id} 
    """

rule run_sim_hap2:
    input: 
        genome = SEED_HAP_2 ## fasta file was artificially mutated with SNPs and Indels
    output:
        bam = temp(output_looper("{seeds}", "{sample}", hap_list[1], SEED_HAP_2_chromnum, cat="sam")),
        ref = temp(output_looper("{seeds}", "{sample}", hap_list[1], SEED_HAP_2_chromnum, cat="ref")),
        maf = temp(output_looper("{seeds}", "{sample}", hap_list[1], SEED_HAP_2_chromnum, cat="maf"))
    params:
        seed_id = "{seeds}",
        prefix_sim = "/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap2/{seeds}_{sample}",
        lngth = config["read_length"],
        dpth = config["depth"]
    resources:
        mem_mb = 100000,
        tmpdir = "/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        module load pbsim3/3.0.0
        pbsim --prefix {params.prefix_sim} --strategy wgs --genome {input.genome} \
        --depth {params.dpth} --method errhmm --errhmm /share/scientific_src/pbsim3/3.0.0/data/ERRHMM-SEQUEL.model \
        --length-mean {params.lngth} --pass-num 10 --seed {params.seed_id} 
    """


rule make_bam1:
    input:
        hap1sam="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap1/{seeds}_{sample}_{chr_nm1}.sam"
        #output_looper("{seeds}", "{sample}", hap_list[0], SEED_HAP_1_chromnum, cat="sam"),
    output:
        hap1bam="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap1/{seeds}_{sample}_{chr_nm1}.bam",
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    threads:
        min(workflow.cores,30)
    shell: """
        module load samtools/1.10
        samtools view -b {input.hap1sam} -o {output.hap1bam} --threads {threads}

    """

rule make_bam2:
    input:
        hap2sam="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap2/{seeds}_{sample}_{chr_nm2}.sam"
    output:
        hap2bam="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap2/{seeds}_{sample}_{chr_nm2}.bam"
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    threads:
        min(workflow.cores,30)
    shell: """
        module load samtools/1.10
        samtools view -b {input.hap2sam} -o {output.hap2bam} --threads {threads}
    """

rule run_ccs1:
    input:
        hap1bam="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap1/{seeds}_{sample}_{chr_nm1}.bam"
    output:
        hap1fastq="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap1/{seeds}_{sample}_{chr_nm1}.fastq.gz"
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    conda:
        "envs/ccs.yml"
    shell: 
        "ccs {input.hap1bam} {output.hap1fastq} -j 5 "

rule run_ccs2:
    input:
        hap2bam="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap2/{seeds}_{sample}_{chr_nm2}.bam"
    output:
        hap2fastq="/share/pool/simulations_collomics/{READ_LENGTH}/{seeds}_{sample}_hap2/{seeds}_{sample}_{chr_nm2}.fastq.gz"
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    conda:
        "envs/ccs.yml"
    shell: 
        "ccs {input.hap2bam} {output.hap2fastq} -j 5"

#######################################


## concatenate reads 

rule cat_fastq:
    input:
        hap1=expand("/share/pool/simulations_collomics/%s/{seeds}_{sample}_{hap}/{seeds}_{sample}_{chr_nm1}.fastq.gz" %READ_LENGTH, seeds=seed_list, hap=hap_list[0], chr_nm1=SEED_HAP_1_chromnum,sample=sample_prefix),
        hap2=expand("/share/pool/simulations_collomics/%s/{seeds}_{sample}_{hap}/{seeds}_{sample}_{chr_nm2}.fastq.gz" %READ_LENGTH, seeds=seed_list, hap=hap_list[1], chr_nm2=SEED_HAP_2_chromnum,sample=sample_prefix)
    output:
        temp("%s/fastq_files/all_pbsim.fastq.gz" %READ_LENGTH)
    shell:
        "cat {input.hap1} {input.hap2} > {output}"


rule hifiasm_assembly:
    input:
        "%s/fastq_files/all_pbsim.fastq.gz" %READ_LENGTH
    output:
        "%s/assembly/pbsim_asm.p_ctg.gfa" %READ_LENGTH
    threads:
        workflow.cores
    params:
        inputpre="%s/assembly/pbsim_asm" %READ_LENGTH
    conda:
        "envs/hifiasm.yml"
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        hifiasm --primary -l2 -t {threads} -o {params.inputpre} {input}
    """

#######################################

## Step 2: Backmapping and stats

## convert gfa to fasta

rule gfa_to_fa:
    input:
        "%s/assembly/pbsim_asm.p_ctg.gfa" %READ_LENGTH
    output:
        "%s/assembly/pbsim_asm.p_ctg.fa" %READ_LENGTH
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        awk '/^S/{{print ">"$2;print $3}}' {input} > {output}
    """

## compute basic summary stats for the assembly

rule assembly_stats:
    input:
        "%s/assembly/pbsim_asm.p_ctg.fa" %READ_LENGTH
    output:
        "%s/stats/assembly_stats.txt" %READ_LENGTH
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell:
        "seqkit stats -a -T {input} > {output}"

#######################################

# BUSCO Score

# -m: genome mode
# -i: input
# -o: output folder
# -l: lineage/database - define it in config file
# --out-path: general folder to place output
# download_path: where to find the lineage/db information
#vertebrata_odb9 and
#tetrapoda_odb9
rule RUN_BUSCO:
    input:
        "%s/assembly/pbsim_asm.p_ctg.fa" %READ_LENGTH
    output:
        "%s/busco/{sample}/run_{db}/missing_busco_list.tsv" %READ_LENGTH
    threads:
        workflow.cores
    params:
        dataset_dir="busco_downloads",
        out_dir="%s/busco/" %READ_LENGTH,
        run_name="{sample}",
        lineage=LINEAGE
    conda:
        "envs/busco.yml"
    resources:
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        busco -f -m genome \
        -c {threads} \
        -i {input} \
        -o {params.run_name} \
        --download_path {params.dataset_dir} \
        --out_path {params.out_dir} \
        -l {params.lineage} \
        --offline
    """
#######################################

## shred assembly into 150 bp long "reads" with 50 bp overlap, creating faux reads with overall 1.5 x coverage
# in a conda environment you should be able to call shred.sh from the terminal like normal
rule backmapping_shredding:
    input:
        "%s/assembly/pbsim_asm.p_ctg.fa" %READ_LENGTH
    output:
        "%s/split_assembly/split_assembly.fa" %READ_LENGTH
    conda:
        "envs/bbtools.yml"
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell:
        "shred.sh -Xmx10g in={input} out={output} length=150 minlength=10 overlap=50"

## map these reads back to the original input file

rule backmapping_mapping:
    input:
        asm = "%s/split_assembly/split_assembly.fa" %READ_LENGTH,
        genome = SEED_HAP_1
    output:
        temp("%s/split_assembly/backmapped.sam" %READ_LENGTH)
    threads:
        config["CORES"]
    conda:
        "envs/bwa.yml"
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        bwa index {input.genome}
        bwa mem {input.genome} {input.asm} -t {threads} > {output}
    """

## convert sam to bam

rule backmapping_bam:
    input:
        "%s/split_assembly/backmapped.sam" %READ_LENGTH
    output:
        temp("%s/split_assembly/backmapped.bam" %READ_LENGTH)
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    threads:
        min(workflow.cores,40)
    shell: """
        module load samtools/1.10
        samtools view -b -o {output} {input} --threads {threads}
    """

## sort bam file

rule backmapping_sort:
    input:
        "%s/split_assembly/backmapped.bam" %READ_LENGTH
    output:
        temp("%s/split_assembly/backmapped.srt.bam" %READ_LENGTH)
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    threads:
        min(workflow.cores,40)
    shell: """
        module load samtools/1.10
        samtools sort {input} --threads {threads} > {output}
    """

## compute average number of bases overlapped by at least one read

rule backmapping_stats:
    input:
        "%s/split_assembly/backmapped.srt.bam" %READ_LENGTH
    output:
        "%s/stats/backmapping_stats.txt" %READ_LENGTH
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell: """
        module load samtools/1.10
        samtools coverage -m -A {input} > {output}
    """

rule read_stats:
    input:
        "%s/fastq_files/all_pbsim.fastq.gz" %READ_LENGTH
    output:
        "%s/stats/read_stats.txt" %READ_LENGTH
    resources:
        mem_mb=100000,
        tmpdir="/share/pool/simulations_collomics/%s/tmp" %READ_LENGTH
    shell:
        "seqkit stats -a -T {input} > {output}"

